{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part D)"
      ],
      "metadata": {
        "id": "8_aO8dyYnyJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "-896nimYn1aP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n"
      ],
      "metadata": {
        "id": "M_ehxA3df4jF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_24 = []\n",
        "X_test_24= []\n",
        "X_train_16 = []\n",
        "X_test_16= []\n",
        "X_train_8 = []\n",
        "X_test_8= []\n",
        "for i in range(len(X_train)):\n",
        "  X_train_24.append(cv2.resize(X_train[i] , (24,24) , interpolation=cv2.INTER_CUBIC  ))\n",
        "  X_train_16.append(cv2.resize(X_train[i] , (16,16) , interpolation=cv2.INTER_CUBIC  ))\n",
        "  X_train_8.append(cv2.resize(X_train[i] , (8,8) , interpolation=cv2.INTER_CUBIC  ))\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  X_test_24.append(cv2.resize(X_test[i] , (24,24) , interpolation=cv2.INTER_CUBIC  ))\n",
        "  X_test_16.append(cv2.resize(X_test[i] , (16,16) , interpolation=cv2.INTER_CUBIC  ))\n",
        "  X_test_8.append(cv2.resize(X_test[i] , (8,8) , interpolation=cv2.INTER_CUBIC  ))\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "X_train_24 = np.array(X_train_24)\n",
        "X_test_24 = np.array(X_test_24)\n",
        "X_train_16 = np.array(X_train_16)\n",
        "X_test_16 = np.array(X_test_16)\n",
        "X_train_8 = np.array(X_train_8)\n",
        "X_test_8 = np.array(X_test_8)\n",
        "\n"
      ],
      "metadata": {
        "id": "vqO6Hm7Nf76n"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_24to32 = []\n",
        "X_test_24to32 = []\n",
        "X_train_16to32 = []\n",
        "X_test_16to32 = []\n",
        "X_train_8to32 = []\n",
        "X_test_8to32 = []\n",
        "\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "  X_train_24to32.append(cv2.resize(X_train_24[i] , (32,32) , interpolation=cv2.INTER_CUBIC ))\n",
        "  X_train_16to32.append(cv2.resize(X_train_16[i] , (32,32) , interpolation=cv2.INTER_CUBIC ))\n",
        "  X_train_8to32.append(cv2.resize(X_train_8[i] , (32,32) , interpolation=cv2.INTER_CUBIC ))\n",
        "\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  X_test_24to32.append(cv2.resize(X_test_24[i] , (32,32) , interpolation=cv2.INTER_CUBIC ))\n",
        "  X_test_16to32.append(cv2.resize(X_test_16[i] , (32,32) , interpolation=cv2.INTER_CUBIC ))\n",
        "  X_test_8to32.append(cv2.resize(X_test_8[i] , (32,32) , interpolation=cv2.INTER_CUBIC ))\n",
        "\n",
        "X_train_24to32 = np.array(X_train_24to32)\n",
        "X_test_24to32 = np.array(X_test_24to32)\n",
        "X_train_16to32 = np.array(X_train_16to32)\n",
        "X_test_16to32 = np.array(X_test_16to32)\n",
        "X_train_8to32 = np.array(X_train_8to32)\n",
        "X_test_8to32 = np.array(X_test_8to32)"
      ],
      "metadata": {
        "id": "iWp8wh2xgHhj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "X_train_24 = X_train_24/255\n",
        "X_test_24 = X_test_24/255\n",
        "X_train_16 = X_train_16/255\n",
        "X_test_16 = X_test_16/255\n",
        "X_train_8 = X_train_8/255\n",
        "X_test_8 = X_test_8/255\n",
        "X_train_24to32 = X_train_24to32/255\n",
        "X_test_24to32 = X_test_24to32/255\n",
        "X_train_16to32 = X_train_16to32/255\n",
        "X_test_16to32 = X_test_16to32/255\n",
        "X_train_8to32 = X_train_8to32/255\n",
        "X_test_8to32 = X_test_8to32/255\n",
        "\n",
        "\n",
        "del X_train_24\n",
        "del X_test_24\n",
        "del X_train_16\n",
        "del X_test_16\n",
        "del X_train_8\n",
        "del X_test_8"
      ],
      "metadata": {
        "id": "B0avfAdAgLQ2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,(3,3),input_shape=(32,32,3),activation='relu'))\n",
        "model.add(Conv2D(32,(3,3),input_shape=(32,32,3),activation='relu'))\n",
        "model.add(Conv2D(32,(3,3),input_shape=(32,32,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64,(3,3),input_shape=(32,32,3),activation='relu'))\n",
        "model.add(Conv2D(64,(3,3),input_shape=(32,32,3),activation='relu'))\n",
        "model.add(Conv2D(64,(3,3),input_shape=(32,32,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10 , activation = 'softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='SGD',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qRcVZtXggNt0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model trained with 24x24 and tested by 24x24"
      ],
      "metadata": {
        "id": "WwkHZjexnYf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "history = model.fit(X_train_24to32, Y_train, epochs = 100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rqfEb0lhtO3",
        "outputId": "88d344e4-9a4b-402f-9324-7c84cc26172b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 13, 13, 32)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 3, 3, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 3, 3, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               295424    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 412,298\n",
            "Trainable params: 412,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 18s 6ms/step - loss: 2.2048 - accuracy: 0.1615\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0157 - accuracy: 0.2436\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.8240 - accuracy: 0.3271\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6632 - accuracy: 0.3890\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5547 - accuracy: 0.4281\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4748 - accuracy: 0.4605\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4025 - accuracy: 0.4893\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3430 - accuracy: 0.5157\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2920 - accuracy: 0.5374\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2546 - accuracy: 0.5497\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2132 - accuracy: 0.5656\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1783 - accuracy: 0.5794\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1480 - accuracy: 0.5913\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1175 - accuracy: 0.6017\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0909 - accuracy: 0.6138\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0654 - accuracy: 0.6229\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0456 - accuracy: 0.6297\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0208 - accuracy: 0.6382\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9979 - accuracy: 0.6465\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9747 - accuracy: 0.6577\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9592 - accuracy: 0.6621\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9395 - accuracy: 0.6696\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9175 - accuracy: 0.6760\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9033 - accuracy: 0.6826\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8870 - accuracy: 0.6892\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8756 - accuracy: 0.6921\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8556 - accuracy: 0.6993\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8472 - accuracy: 0.7038\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8298 - accuracy: 0.7088\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8223 - accuracy: 0.7136\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8052 - accuracy: 0.7176\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7961 - accuracy: 0.7201\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7819 - accuracy: 0.7265\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7742 - accuracy: 0.7289\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7642 - accuracy: 0.7317\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7530 - accuracy: 0.7337\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7457 - accuracy: 0.7379\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7357 - accuracy: 0.7409\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7244 - accuracy: 0.7447\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7140 - accuracy: 0.7490\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7067 - accuracy: 0.7516\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7009 - accuracy: 0.7562\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6948 - accuracy: 0.7562\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6853 - accuracy: 0.7593\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6800 - accuracy: 0.7619\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6730 - accuracy: 0.7645\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6657 - accuracy: 0.7665\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6570 - accuracy: 0.7684\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6511 - accuracy: 0.7706\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6465 - accuracy: 0.7709\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6391 - accuracy: 0.7747\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6349 - accuracy: 0.7762\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6257 - accuracy: 0.7795\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6199 - accuracy: 0.7812\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6123 - accuracy: 0.7836\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6103 - accuracy: 0.7859\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6053 - accuracy: 0.7875\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5992 - accuracy: 0.7880\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5933 - accuracy: 0.7897\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5910 - accuracy: 0.7910\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5848 - accuracy: 0.7937\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5774 - accuracy: 0.7957\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5737 - accuracy: 0.7978\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5704 - accuracy: 0.7996\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5689 - accuracy: 0.7987\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5624 - accuracy: 0.8007\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5528 - accuracy: 0.8051\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5519 - accuracy: 0.8036\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5510 - accuracy: 0.8042\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5443 - accuracy: 0.8076\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5396 - accuracy: 0.8091\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5328 - accuracy: 0.8096\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5305 - accuracy: 0.8111\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5270 - accuracy: 0.8139\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5238 - accuracy: 0.8138\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5209 - accuracy: 0.8145\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5186 - accuracy: 0.8136\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5119 - accuracy: 0.8187\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5133 - accuracy: 0.8182\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5028 - accuracy: 0.8212\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4996 - accuracy: 0.8227\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4941 - accuracy: 0.8245\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4952 - accuracy: 0.8227\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4909 - accuracy: 0.8235\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4853 - accuracy: 0.8267\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4883 - accuracy: 0.8274\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4857 - accuracy: 0.8263\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4757 - accuracy: 0.8299\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4770 - accuracy: 0.8296\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4716 - accuracy: 0.8323\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4702 - accuracy: 0.8309\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4667 - accuracy: 0.8321\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4625 - accuracy: 0.8349\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4605 - accuracy: 0.8342\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4562 - accuracy: 0.8369\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4541 - accuracy: 0.8362\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4574 - accuracy: 0.8353\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4542 - accuracy: 0.8368\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4500 - accuracy: 0.8393\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4441 - accuracy: 0.8410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test_24to32)\n",
        "y_label=np.argmax(y_pred , axis=1)\n",
        "print('accuracy: ',metrics.accuracy_score(Y_test, y_label))\n",
        "print('CL Report: \\n',metrics.classification_report(Y_test, y_label, zero_division=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zUL7FoviTq9",
        "outputId": "e23bff5c-728a-44d9-d8c1-ca828be852d3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "accuracy:  0.4824\n",
            "CL Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.72      0.58      1000\n",
            "           1       0.45      0.88      0.59      1000\n",
            "           2       0.91      0.10      0.18      1000\n",
            "           3       0.52      0.19      0.28      1000\n",
            "           4       0.75      0.09      0.16      1000\n",
            "           5       0.55      0.50      0.53      1000\n",
            "           6       0.76      0.27      0.40      1000\n",
            "           7       0.43      0.75      0.55      1000\n",
            "           8       0.38      0.56      0.45      1000\n",
            "           9       0.51      0.77      0.61      1000\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.57      0.48      0.43     10000\n",
            "weighted avg       0.57      0.48      0.43     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model trained with 16x16 and tested by 16x16"
      ],
      "metadata": {
        "id": "8vtNWqbZn86G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "history = model.fit(X_train_16to32, Y_train, epochs = 100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9awcKVgoBzp",
        "outputId": "db828341-ccad-4743-a08c-59f03904ea93"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 26, 26, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 13, 13, 32)        0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 3, 3, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3, 3, 64)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               295424    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 412,298\n",
            "Trainable params: 412,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.2366 - accuracy: 0.1762\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.9005 - accuracy: 0.2931\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7387 - accuracy: 0.3595\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6264 - accuracy: 0.4056\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5469 - accuracy: 0.4391\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4877 - accuracy: 0.4634\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4420 - accuracy: 0.4816\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4020 - accuracy: 0.4951\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3697 - accuracy: 0.5087\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3498 - accuracy: 0.5168\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3153 - accuracy: 0.5332\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2922 - accuracy: 0.5397\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2748 - accuracy: 0.5431\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2529 - accuracy: 0.5532\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2362 - accuracy: 0.5590\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2176 - accuracy: 0.5665\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2050 - accuracy: 0.5719\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1987 - accuracy: 0.5753\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1791 - accuracy: 0.5836\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1661 - accuracy: 0.5876\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1520 - accuracy: 0.5892\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1361 - accuracy: 0.5973\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1262 - accuracy: 0.5974\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1164 - accuracy: 0.6062\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1050 - accuracy: 0.6067\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0947 - accuracy: 0.6146\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0824 - accuracy: 0.6165\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0770 - accuracy: 0.6186\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0651 - accuracy: 0.6229\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0655 - accuracy: 0.6250\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0535 - accuracy: 0.6296\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0454 - accuracy: 0.6320\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0367 - accuracy: 0.6363\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0263 - accuracy: 0.6371\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0164 - accuracy: 0.6402\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0131 - accuracy: 0.6429\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0062 - accuracy: 0.6474\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0028 - accuracy: 0.6481\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9949 - accuracy: 0.6478\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9916 - accuracy: 0.6513\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9821 - accuracy: 0.6557\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9791 - accuracy: 0.6554\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9675 - accuracy: 0.6600\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9682 - accuracy: 0.6590\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9629 - accuracy: 0.6594\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9563 - accuracy: 0.6644\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9534 - accuracy: 0.6649\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9507 - accuracy: 0.6656\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9381 - accuracy: 0.6679\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9388 - accuracy: 0.6715\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9303 - accuracy: 0.6738\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9296 - accuracy: 0.6722\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9234 - accuracy: 0.6745\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9270 - accuracy: 0.6748\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9164 - accuracy: 0.6789\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9120 - accuracy: 0.6802\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9101 - accuracy: 0.6843\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9021 - accuracy: 0.6845\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8994 - accuracy: 0.6849\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8944 - accuracy: 0.6894\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8868 - accuracy: 0.6865\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8877 - accuracy: 0.6879\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8860 - accuracy: 0.6878\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8877 - accuracy: 0.6900\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8812 - accuracy: 0.6899\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8828 - accuracy: 0.6927\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8668 - accuracy: 0.6976\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8709 - accuracy: 0.6951\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8689 - accuracy: 0.6977\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8744 - accuracy: 0.6944\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8660 - accuracy: 0.6959\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8601 - accuracy: 0.6984\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8609 - accuracy: 0.6992\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8551 - accuracy: 0.7018\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8545 - accuracy: 0.7002\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8478 - accuracy: 0.7033\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8548 - accuracy: 0.7017\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8443 - accuracy: 0.7031\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8501 - accuracy: 0.7029\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8449 - accuracy: 0.7039\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8497 - accuracy: 0.7027\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8412 - accuracy: 0.7074\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8381 - accuracy: 0.7045\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8418 - accuracy: 0.7058\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8395 - accuracy: 0.7067\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8298 - accuracy: 0.7087\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8293 - accuracy: 0.7100\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8193 - accuracy: 0.7123\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8237 - accuracy: 0.7122\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8304 - accuracy: 0.7085\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8210 - accuracy: 0.7109\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8238 - accuracy: 0.7110\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8295 - accuracy: 0.7085\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8126 - accuracy: 0.7152\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8146 - accuracy: 0.7138\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8237 - accuracy: 0.7099\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8159 - accuracy: 0.7126\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8129 - accuracy: 0.7166\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8161 - accuracy: 0.7138\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8098 - accuracy: 0.7158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test_16to32)\n",
        "y_label=np.argmax(y_pred , axis=1)\n",
        "print('accuracy: ',metrics.accuracy_score(Y_test, y_label))\n",
        "print('CL Report: \\n',metrics.classification_report(Y_test, y_label, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOG-JsNnoGpd",
        "outputId": "162c1ce7-dcc2-42ff-d81c-4113bee90436"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "accuracy:  0.6893\n",
            "CL Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.64      0.70      1000\n",
            "           1       0.82      0.82      0.82      1000\n",
            "           2       0.59      0.62      0.61      1000\n",
            "           3       0.45      0.58      0.51      1000\n",
            "           4       0.68      0.62      0.65      1000\n",
            "           5       0.63      0.55      0.59      1000\n",
            "           6       0.70      0.81      0.75      1000\n",
            "           7       0.79      0.67      0.73      1000\n",
            "           8       0.75      0.81      0.78      1000\n",
            "           9       0.80      0.76      0.78      1000\n",
            "\n",
            "    accuracy                           0.69     10000\n",
            "   macro avg       0.70      0.69      0.69     10000\n",
            "weighted avg       0.70      0.69      0.69     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model trained with 8x8 and tested by 8x8"
      ],
      "metadata": {
        "id": "cYf_u78doMAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "history = model.fit(X_train_8to32, Y_train, epochs = 100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Va2g5KoPFO",
        "outputId": "c10fb729-f190-4bc1-8059-87114b218173"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 26, 26, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 13, 13, 32)        0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 3, 3, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 3, 3, 64)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               295424    \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 412,298\n",
            "Trainable params: 412,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 2.2201 - accuracy: 0.1903\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.9632 - accuracy: 0.2652\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8357 - accuracy: 0.3170\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7598 - accuracy: 0.3499\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7075 - accuracy: 0.3704\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6650 - accuracy: 0.3898\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6374 - accuracy: 0.4014\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6133 - accuracy: 0.4108\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5880 - accuracy: 0.4236\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5705 - accuracy: 0.4291\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5535 - accuracy: 0.4380\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5301 - accuracy: 0.4468\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5209 - accuracy: 0.4504\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5053 - accuracy: 0.4552\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4879 - accuracy: 0.4588\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4769 - accuracy: 0.4673\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4660 - accuracy: 0.4719\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4586 - accuracy: 0.4715\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4468 - accuracy: 0.4763\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4334 - accuracy: 0.4830\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4302 - accuracy: 0.4852\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4212 - accuracy: 0.4901\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4153 - accuracy: 0.4887\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4033 - accuracy: 0.4933\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3954 - accuracy: 0.4976\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3867 - accuracy: 0.5020\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3809 - accuracy: 0.4997\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3806 - accuracy: 0.5039\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3703 - accuracy: 0.5060\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3674 - accuracy: 0.5085\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3561 - accuracy: 0.5143\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3536 - accuracy: 0.5142\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3480 - accuracy: 0.5178\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3432 - accuracy: 0.5195\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3379 - accuracy: 0.5186\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3314 - accuracy: 0.5224\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3229 - accuracy: 0.5278\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3245 - accuracy: 0.5255\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3171 - accuracy: 0.5280\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3107 - accuracy: 0.5323\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3090 - accuracy: 0.5351\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3056 - accuracy: 0.5324\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2985 - accuracy: 0.5344\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2926 - accuracy: 0.5367\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2967 - accuracy: 0.5354\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2847 - accuracy: 0.5403\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2832 - accuracy: 0.5416\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2761 - accuracy: 0.5439\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2781 - accuracy: 0.5440\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2736 - accuracy: 0.5450\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2660 - accuracy: 0.5466\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2703 - accuracy: 0.5451\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2575 - accuracy: 0.5472\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2550 - accuracy: 0.5512\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2528 - accuracy: 0.5498\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2526 - accuracy: 0.5506\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2479 - accuracy: 0.5551\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2441 - accuracy: 0.5541\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2492 - accuracy: 0.5538\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2374 - accuracy: 0.5559\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2404 - accuracy: 0.5548\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2400 - accuracy: 0.5562\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2361 - accuracy: 0.5576\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2318 - accuracy: 0.5585\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2363 - accuracy: 0.5588\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2275 - accuracy: 0.5610\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2233 - accuracy: 0.5628\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2282 - accuracy: 0.5614\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2229 - accuracy: 0.5618\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2190 - accuracy: 0.5622\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2177 - accuracy: 0.5657\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2169 - accuracy: 0.5674\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2122 - accuracy: 0.5661\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2078 - accuracy: 0.5677\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2032 - accuracy: 0.5697\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2053 - accuracy: 0.5670\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2092 - accuracy: 0.5672\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2014 - accuracy: 0.5715\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2005 - accuracy: 0.5702\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1955 - accuracy: 0.5715\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1967 - accuracy: 0.5709\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1915 - accuracy: 0.5721\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1870 - accuracy: 0.5737\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1901 - accuracy: 0.5751\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1905 - accuracy: 0.5746\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1831 - accuracy: 0.5755\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1805 - accuracy: 0.5799\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1837 - accuracy: 0.5762\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1857 - accuracy: 0.5741\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1884 - accuracy: 0.5757\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1755 - accuracy: 0.5780\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1823 - accuracy: 0.5777\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1739 - accuracy: 0.5812\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1696 - accuracy: 0.5799\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1658 - accuracy: 0.5836\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1689 - accuracy: 0.5833\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1714 - accuracy: 0.5812\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1729 - accuracy: 0.5781\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1697 - accuracy: 0.5821\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1658 - accuracy: 0.5834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test_8to32)\n",
        "y_label=np.argmax(y_pred , axis=1)\n",
        "print('accuracy: ',metrics.accuracy_score(Y_test, y_label))\n",
        "print('CL Report: \\n',metrics.classification_report(Y_test, y_label, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jORo-4NaoSBH",
        "outputId": "3b4d328c-fa23-42a8-defd-cc16c4c3efa6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n",
            "accuracy:  0.5434\n",
            "CL Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.59      0.61      1000\n",
            "           1       0.71      0.66      0.68      1000\n",
            "           2       0.52      0.36      0.42      1000\n",
            "           3       0.32      0.52      0.40      1000\n",
            "           4       0.47      0.55      0.51      1000\n",
            "           5       0.47      0.37      0.41      1000\n",
            "           6       0.56      0.66      0.61      1000\n",
            "           7       0.67      0.55      0.60      1000\n",
            "           8       0.63      0.66      0.65      1000\n",
            "           9       0.63      0.50      0.56      1000\n",
            "\n",
            "    accuracy                           0.54     10000\n",
            "   macro avg       0.56      0.54      0.55     10000\n",
            "weighted avg       0.56      0.54      0.55     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}