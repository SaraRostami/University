{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gVQ9Q4lw4_XA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7xU1WDCtLvd"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "prl-PotP4gNl"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(layers.Layer):\n",
    "    def __init__(self, hidden_size, num_heads):\n",
    "\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.projection_dim = hidden_size // num_heads\n",
    "        self.Q = layers.Dense(hidden_size)\n",
    "        self.K = layers.Dense(hidden_size)\n",
    "        self.V = layers.Dense(hidden_size)\n",
    "        self.out = layers.Dense(hidden_size)\n",
    "\n",
    "    def attention(self, query, key, value, mask):\n",
    "        \n",
    "\n",
    "        attention_scores = tf.matmul(query, key, transpose_b=True)\n",
    "        attention_scores = attention_scores / tf.sqrt(float(self.hidden_size))\n",
    "        \n",
    "        adder = (1.0 - tf.cast(mask, tf.float32)) # * self.params.negative_infinity\n",
    "        attention_scores = tf.add(attention_scores, adder)\n",
    "        \n",
    "        weights = tf.nn.softmax(attention_scores)\n",
    "\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs, att_mask):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.separate_heads(self.Q(inputs)  , batch_size)  \n",
    "        key = self.separate_heads(self.K(inputs), batch_size)  \n",
    "        value = self.separate_heads(self.V(inputs) , batch_size) \n",
    "        attention, self.att_weights = self.attention(query, key, value, att_mask)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.hidden_size))\n",
    "        output = self.out(concat_attention)  \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCVLJBv951nW"
   },
   "source": [
    "#### Feed-Forward Sub-Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRnFXb0WwwSB"
   },
   "source": [
    "Unlike the original transformer, BERT uses \"GELU\" activation function. In this part you should implement the GELU activation function based on the paper provided to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qzD7BjELQ--j"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "\n",
    "def GELU(x):\n",
    "    cdf = 0.5 * (1.0 + tf.tanh(\n",
    "          (np.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3)))))\n",
    "    return x * cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Gqd6wedZXxzD"
   },
   "outputs": [],
   "source": [
    "class FFN(layers.Layer):\n",
    "\n",
    "    def __init__(self, intermediate_size, hidden_size, drop_rate):\n",
    "\n",
    "        super(FFN, self).__init__()\n",
    "        self.intermediate = layers.Dense(intermediate_size, activation=GELU, kernel_initializer=TruncatedNormal(stddev=0.02))\n",
    "        self.out = layers.Dense(hidden_size, kernel_initializer=TruncatedNormal(stddev=0.02))\n",
    "        self.drop = layers.Dropout(drop_rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.intermediate(inputs)\n",
    "        x = self.out(x)\n",
    "        x = self.drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDlwb3Ea6Aqc"
   },
   "source": [
    "#### Add & Norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4-UMLpDUkFa"
   },
   "source": [
    "In this part implement the add & norm blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_TtnesNMOHUF"
   },
   "outputs": [],
   "source": [
    "class AddNorm(layers.Layer):\n",
    "\n",
    "    def __init__(self, LNepsilon, drop_rate):\n",
    "    \n",
    "        super(AddNorm, self).__init__()\n",
    "        self.LN = layers.LayerNormalization(epsilon=LNepsilon)\n",
    "        self.dropout = layers.Dropout(drop_rate)\n",
    "\n",
    "    def call(self, sub_layer_in, sub_layer_out):\n",
    "        x = self.LN(sub_layer_in+sub_layer_out)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKqyg0J_WuTv"
   },
   "source": [
    "#### Residual connections\n",
    "\n",
    "Now put together all parts and build the encoder with the residual connections\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "16zvGFBo_uaQ"
   },
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "\n",
    "    def __init__(self, hidden_size, num_heads, intermediate_size, drop_rate=0.1, LNepsilon=1e-12):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.attention = MultiHeadAttention(hidden_size, num_heads)\n",
    "\n",
    "        #self.ffn = [FFN(intermediate_size, hidden_size, drop_rate) for i in range(num_heads)]\n",
    "        self.ffn = FFN(intermediate_size, hidden_size, drop_rate)\n",
    "        self.addN = AddNorm(LNepsilon, drop_rate)\n",
    "\n",
    "    def call(self, inputs, mask):\n",
    "        x = self.attention(inputs, mask)\n",
    "        x = self.addN(x, inputs)\n",
    "        xf = self.ffn(x)\n",
    "        xf = self.addN(xf, x)\n",
    "        \n",
    "        return xf\n",
    "\n",
    "    def compute_mask(self, x, mask):\n",
    "        #print(\"mask   \", mask.shape)\n",
    "        x = tf.transpose(x, perm=[0,2,1])\n",
    "        x = tf.multiply(x, mask[:,0,0,:])\n",
    "        x = tf.transpose(x, perm=[0,2,1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umQ878ho-6Hp"
   },
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "DTW-F4t9_x24"
   },
   "outputs": [],
   "source": [
    "class BertEmbedding(layers.Layer):\n",
    "\n",
    "    def __init__(self, vocab_size, maxlen, hidden_size):\n",
    "\n",
    "        super(BertEmbedding, self).__init__()\n",
    "        self.TokEmb = layers.Embedding(input_dim=vocab_size, output_dim=hidden_size, mask_zero=True)\n",
    "        self.PosEmb = tf.Variable(tf.random.truncated_normal(shape=(maxlen, hidden_size), stddev=0.02))\n",
    "        self.LN = layers.LayerNormalization(epsilon=1e-12)\n",
    "        self.dropout = layers.Dropout(0.1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        temb = self.TokEmb(inputs)\n",
    "        pemb = self.TokEmb(inputs)\n",
    "        x = self.LN(temb+pemb)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    def compute_mask(self, x, mask=None):\n",
    "        m = 1-tf.cast(self.TokEmb.compute_mask(x), tf.float32)\n",
    "        m = m[:, tf.newaxis, tf.newaxis, :]\n",
    "        return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPjWqcH-ytQP"
   },
   "source": [
    "The \"pooler\" is the last layer you need to put in place.\n",
    "For each input sentence, the pooler changes the hidden states of the last encoder layer (which have the shape [batch size, sequence lenght, hidden size]) into a vector representation (which has the shape [batch size, hidden size]).\n",
    "The pooler does this by giving a dense layer the hidden state that goes with the first token, which is a special token at the beginning of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "O719umhMz_UH"
   },
   "outputs": [],
   "source": [
    "class Pooler(layers.Layer):\n",
    "\n",
    "    def __init__(self, hidden_size):\n",
    "\n",
    "        super(Pooler, self).__init__()\n",
    "        #self.dense = layers.Dense(hidden_size, activation='tanh')\n",
    "        self.dense = layers.Dense(1, activation='tanh')\n",
    "\n",
    "    def call(self, encoder_out):\n",
    "        first_token_tensor = encoder_out[:, 0]\n",
    "        x = self.dense(first_token_tensor)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-P8zt_tFojZY"
   },
   "source": [
    "Now you should complete the **create_BERT** function in the cell below. This function gets BERT's hyper-parameters as its inputs and return a BERT model. \n",
    "Note that the returned model must have two outputs (just like the pre-trained BERTs): \n",
    "- The hidden states of the last encoder layer\n",
    "- Output of the pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "L9tD7UtNfZ4p"
   },
   "outputs": [],
   "source": [
    "def create_BERT(vocab_size, maxlen, hidden_size, num_layers, num_att_heads, intermediate_size, drop_rate=0.1):\n",
    "\n",
    "    \"\"\"\n",
    "    creates a BERT model based on the arguments provided\n",
    "\n",
    "        Arguments:\n",
    "        vocab_size: number of words in the vocabulary\n",
    "        maxlen: maximum length of each sentence\n",
    "        hidden_size: dimension of the hidden state of each encoder layer\n",
    "        num_layers: number of encoder layers\n",
    "        num_att_heads: number of attention heads in the multi-headed attention layer\n",
    "        intermediate_size: dimension of the intermediate layer in the feed-forward sublayer of the encoders\n",
    "        drop_rate: dropout rate of all the dropout layers used in the model\n",
    "        returns: \n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=(32,))\n",
    "    embed = BertEmbedding(vocab_size, maxlen, hidden_size)\n",
    "    emb = embed(inputs)\n",
    "    mask = embed.compute_mask(inputs)\n",
    "    #print(\" ----    mask   \", mask.shape)\n",
    "    enc = Encoder(hidden_size, num_att_heads, intermediate_size, drop_rate)(emb, mask)\n",
    "    #print(\"enc  \", enc.shape)\n",
    "    \n",
    "    pool = Pooler(hidden_size)(enc)\n",
    "    #print(\"pool   \", pool.shape)\n",
    "    model = tf.keras.Model(inputs, pool)\n",
    "    #model = tf.keras.Model(inputs, (pool, enc[-1]))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKBEBTI6sFKu"
   },
   "source": [
    "We will use the Rotten tomatoes critic reviews dataset for this assignment. The zip file is provided to you. Unzip it and run the cells below to split the dataset in training and test sets and prepare it for feeding to the bert model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IUn-48AVXbfR"
   },
   "outputs": [],
   "source": [
    "train_reviews, test_reviews = pd.read_csv('train_reviews.csv').values[:, 1:], pd.read_csv('test_reviews.csv').values[:, 1:]\n",
    "(train_texts, train_labels), (test_texts, test_labels)  = (train_reviews[:,0],train_reviews[:,1]), (test_reviews[:,0],test_reviews[:,1]) \n",
    "train_texts = [s.lower() for s in train_texts]\n",
    "test_texts = [s.lower() for s in test_texts] \n",
    "aprx_vocab_size = 20000\n",
    "cls_token = '[cls]'\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(corpus_generator=train_texts,\n",
    "                                                        target_vocab_size=aprx_vocab_size,\n",
    "                                                        reserved_tokens=[cls_token])                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhTvBa9ntO7b"
   },
   "source": [
    "In the following cell, you need to complete the implementation of the encode_sentence function. This function takes as input a sentence and an integer representing the maximum length of the sentence and returns a list of token ids. To implement this function, follow these steps:\n",
    "\n",
    "-Use the trained tokenizer to encode the input sentence and obtain a list of token ids.\n",
    "\n",
    "-Pad the token id list with zeros to the maximum length specified.\n",
    "\n",
    "-Prepend the id of the special token to the beginning of the token id list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nzO4yiJSmIRs"
   },
   "outputs": [],
   "source": [
    "def encode_sentence(s, maxlen):\n",
    "    ret = [0 for i in range(maxlen)]\n",
    "    tok_id_list = tokenizer.encode(s)\n",
    "    m = min(len(tok_id_list), maxlen)\n",
    "    ret[:m] = tok_id_list[:m]\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "rL-PTRJPYnPb"
   },
   "outputs": [],
   "source": [
    "MAXLEN = 32\n",
    "x_train = np.array([encode_sentence(x, MAXLEN) for x in train_texts], dtype=np.int64)\n",
    "x_test = np.array([encode_sentence(x, MAXLEN) for x in test_texts], dtype=np.int64)\n",
    "y_train = train_labels.astype(np.int64)\n",
    "y_test = test_labels.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252150, 32)\n",
      "(252150,)\n",
      "(84051, 32)\n",
      "(84051,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBirx1Fbvv-k"
   },
   "source": [
    "Now use the functional api and the **create_BERT** function you implemented earlier to create a classifier for the movie reviews dataset.\n",
    "Note that the intermediate layer in the feed-forward sub-layer of the encoders is set to $4\\times H$ in the original BERT implementation, where $H$ is the hidden layer size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "SZOW4L9gBqvc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----    mask    (None, 1, 1, 32)\n",
      "enc   (None, 32, 768)\n",
      "p1    (None, 32, 768)\n",
      "p2    (None, 768)\n",
      "p3    (None, 1)\n",
      "pool    (None, 1)\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 768\n",
    "num_heads = 12\n",
    "num_layers = 12\n",
    "vocab_size = tokenizer.vocab_size  \n",
    "\n",
    "#### complete this part ####\n",
    "model = create_BERT(vocab_size, MAXLEN, hidden_size, num_layers, num_heads, intermediate_size=12, drop_rate=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "RwBQt1bFBwYh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.not_equal_4 (TFOpLambda (None, 32)           0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_4 (TFOpLambda)          (None, 32)           0           tf.math.not_equal_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_4 (TFOpLambda) (None, 32)           0           tf.cast_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bert_embedding_4 (BertEmbedding (None, 32, 768)      15356928    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_5 (Sli (None, 1, 1, 32)     0           tf.math.subtract_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4 (Encoder)             (None, 32, 768)      2383116     bert_embedding_4[0][0]           \n",
      "                                                                 tf.__operators__.getitem_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "pooler_4 (Pooler)               (None, 1)            769         encoder_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,740,813\n",
      "Trainable params: 17,740,813\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(learning_rate=5e-5), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "4IwB37mHByJ0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1970/1970 [==============================] - ETA: 0s - loss: 0.9395 - accuracy: 0.6408p1    (None, 32, 768)\n",
      "p2    (None, 768)\n",
      "p3    (None, 1)\n",
      "1970/1970 [==============================] - 1531s 777ms/step - loss: 0.9395 - accuracy: 0.6408 - val_loss: 0.5961 - val_accuracy: 0.7005\n",
      "Epoch 2/2\n",
      "1970/1970 [==============================] - 1531s 777ms/step - loss: 0.7847 - accuracy: 0.6853 - val_loss: 0.5596 - val_accuracy: 0.7383\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=2,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPfMQS1ZsHHk"
   },
   "source": [
    "### Attention Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cellView": "form",
    "id": "jwGoqnHXadiF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bertviz_repo'...\n",
      "remote: Enumerating objects: 1625, done.\u001b[K\n",
      "remote: Counting objects: 100% (321/321), done.\u001b[K\n",
      "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
      "remote: Total 1625 (delta 226), reused 220 (delta 208), pack-reused 1304\u001b[K\n",
      "Receiving objects: 100% (1625/1625), 198.36 MiB | 825.00 KiB/s, done.\n",
      "Resolving deltas: 100% (1068/1068), done.\n"
     ]
    }
   ],
   "source": [
    "#@title Run this!\n",
    "import sys\n",
    "\n",
    "!test -d bertviz_repo && echo \"FYI: bertviz_repo directory already exists, to pull latest version uncomment this line: !rm -r bertviz_repo\"\n",
    "# !rm -r bertviz_repo # Uncomment if you need a clean pull from repo\n",
    "!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n",
    "if not 'bertviz_repo' in sys.path:\n",
    "    sys.path += ['bertviz_repo']\n",
    "\n",
    "from bertviz import head_view\n",
    "\n",
    "def call_html():\n",
    "    import IPython\n",
    "    display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
    "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9p5EleW-6EaN"
   },
   "source": [
    "In order to use bertviz, we need to obtain the attention weights in the encoders of the BERT model implemented in the previous section. To do this, you need to complete the implementation of the get_att_weights function in the following cell. This function takes as input a model (the trained BERT-based model from the previous section) and a list of tokens (an encoded sentence). Here's what you need to do:\n",
    "\n",
    "-Feed the input token list to the model to generate the attention weights for that input.\n",
    "\n",
    "-Access the att_weights attribute of the MultiHeadAttention sub-layer of each encoder in the model and add them all to a list.\n",
    "\n",
    "-Return the list (which should be a list of Tensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "lUsR5r4Z-Pd7"
   },
   "outputs": [],
   "source": [
    "def get_att_weights(model, tok_id_list):\n",
    "    tok_id_list = np.array(tok_id_list)\n",
    "    tok_id_list = tok_id_list[np.newaxis, :]\n",
    "    \n",
    "    tok_id_list = tf.convert_to_tensor(tok_id_list)\n",
    "    out = model(tok_id_list)\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        if layer.name.startswith('encoder'):\n",
    "            att_weights = layer.attention.get_weights()\n",
    "    #print(\"att  \", att_weights)\n",
    "    return att_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "jaV7YOtuBQeC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def get_att_tok(model, sent):\n",
    "\n",
    "    maxlen = model.layers[0].input_shape[0][-1]\n",
    "    encoded_toks = encode_sentence(sent, maxlen)\n",
    "    att_weights = get_att_weights(model, encoded_toks)\n",
    "    pad_start_idx = np.min(np.where(np.array(encoded_toks) == 0))\n",
    "    toks = encoded_toks[:pad_start_idx]\n",
    "    atts = []\n",
    "    for att in att_weights:\n",
    "        #print(\"att  \", att.shape)\n",
    "        if len(att.shape) == 2:\n",
    "            layer_att = torch.FloatTensor(att[np.newaxis,np.newaxis,:pad_start_idx, :pad_start_idx])\n",
    "        atts.append(layer_att)\n",
    "    toks = [tokenizer.decode([m]) for m in toks]\n",
    "    return toks, atts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOhd420dk8Ld"
   },
   "source": [
    "#### Attention visualization\n",
    "now give a sample sentence in the context of giving your opinion about a movie and visualize the attention. for example \"I liked that movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "65xPcS1VIWyc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1    (1, 32, 768)\n",
      "p2    (1, 768)\n",
      "p3    (1, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "        <script>\n",
       "          requirejs.config({\n",
       "            paths: {\n",
       "              base: '/static/base',\n",
       "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n",
       "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
       "            },\n",
       "          });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "      \n",
       "        <div id=\"bertviz-ca6f7496c1df4774ac9b5b0d3833bd4b\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
       "            <span style=\"user-select:none\">\n",
       "                Layer: <select id=\"layer\"></select>\n",
       "                \n",
       "            </span>\n",
       "            <div id='vis'></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/**\n",
       " * @fileoverview Transformer Visualization D3 javascript code.\n",
       " *\n",
       " *\n",
       " *  Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
       " *\n",
       " * Change log:\n",
       " *\n",
       " * 12/19/18  Jesse Vig   Assorted cleanup. Changed orientation of attention matrices.\n",
       " * 12/29/20  Jesse Vig   Significant refactor.\n",
       " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
       " * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n",
       " * 05/03/21  Jesse Vig   Adjust height of visualization dynamically\n",
       " * 07/25/21  Jesse Vig   Support layer filtering\n",
       " * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n",
       " **/\n",
       "\n",
       "require.config({\n",
       "  paths: {\n",
       "      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n",
       "    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
       "  }\n",
       "});\n",
       "\n",
       "requirejs(['jquery', 'd3'], function ($, d3) {\n",
       "\n",
       "    const params = {\"attention\": [{\"name\": null, \"attn\": [[[[0.005308747757226229, 0.02792586013674736, 0.012444875203073025, 0.051662642508745193, -0.032666902989149094, 0.03962425887584686, -0.06341620534658432, -0.034399811178445816, -0.029896222054958344], [0.01534015592187643, -0.05293969064950943, 0.04813876748085022, 0.04369467496871948, -0.038243576884269714, 0.047391992062330246, 0.045103419572114944, -0.024966251105070114, -0.02024153061211109], [0.005885178688913584, 0.05363861843943596, 0.056672170758247375, -0.03855070844292641, 0.04591817036271095, -0.04247843101620674, -0.024459481239318848, 0.02769896574318409, -0.014317071065306664], [-0.0594935268163681, 0.01567590981721878, -0.0054655964486300945, 0.03161740303039551, 0.023045942187309265, -0.010685225948691368, -0.00529899587854743, 0.03432264178991318, 0.04537812992930412], [-0.056299641728401184, 0.013876128941774368, -0.04355517029762268, 0.018834900110960007, -0.021165167912840843, -0.03942957520484924, 0.04956173524260521, -0.049048151820898056, -0.002499617636203766], [0.04833441972732544, -0.012594245374202728, 0.013872274197638035, -0.04767740145325661, 0.003250666195526719, -0.036340706050395966, -0.05191194266080856, 0.018004637211561203, 0.003871646709740162], [0.017765672877430916, 0.03296053782105446, 0.05163554474711418, 0.021378953009843826, -0.056017663329839706, -0.0029373024590313435, -0.05167132243514061, -0.014652512036263943, -0.04398360475897789], [-0.05875718221068382, 0.013315537944436073, -0.028150252997875214, -0.04426280036568642, 0.046556778252124786, -0.03432033583521843, 0.03840509057044983, 0.0370270274579525, 0.009281065315008163], [0.0508430115878582, 0.010180911980569363, 0.024445349350571632, -0.06080879271030426, -0.03303331881761551, 0.006515083368867636, 0.017452266067266464, 0.021060768514871597, 0.05783354490995407]]], [[[0.005308747757226229, 0.02792586013674736, 0.012444875203073025, 0.051662642508745193, -0.032666902989149094, 0.03962425887584686, -0.06341620534658432, -0.034399811178445816, -0.029896222054958344], [0.01534015592187643, -0.05293969064950943, 0.04813876748085022, 0.04369467496871948, -0.038243576884269714, 0.047391992062330246, 0.045103419572114944, -0.024966251105070114, -0.02024153061211109], [0.005885178688913584, 0.05363861843943596, 0.056672170758247375, -0.03855070844292641, 0.04591817036271095, -0.04247843101620674, -0.024459481239318848, 0.02769896574318409, -0.014317071065306664], [-0.0594935268163681, 0.01567590981721878, -0.0054655964486300945, 0.03161740303039551, 0.023045942187309265, -0.010685225948691368, -0.00529899587854743, 0.03432264178991318, 0.04537812992930412], [-0.056299641728401184, 0.013876128941774368, -0.04355517029762268, 0.018834900110960007, -0.021165167912840843, -0.03942957520484924, 0.04956173524260521, -0.049048151820898056, -0.002499617636203766], [0.04833441972732544, -0.012594245374202728, 0.013872274197638035, -0.04767740145325661, 0.003250666195526719, -0.036340706050395966, -0.05191194266080856, 0.018004637211561203, 0.003871646709740162], [0.017765672877430916, 0.03296053782105446, 0.05163554474711418, 0.021378953009843826, -0.056017663329839706, -0.0029373024590313435, -0.05167132243514061, -0.014652512036263943, -0.04398360475897789], [-0.05875718221068382, 0.013315537944436073, -0.028150252997875214, -0.04426280036568642, 0.046556778252124786, -0.03432033583521843, 0.03840509057044983, 0.0370270274579525, 0.009281065315008163], [0.0508430115878582, 0.010180911980569363, 0.024445349350571632, -0.06080879271030426, -0.03303331881761551, 0.006515083368867636, 0.017452266067266464, 0.021060768514871597, 0.05783354490995407]]], [[[-0.03548387438058853, -0.042521581053733826, 0.0044430517591536045, 0.04627595469355583, -0.03532065451145172, 0.022845670580863953, 0.007194217294454575, 0.048957616090774536, -0.004721544217318296], [-0.017810676246881485, 0.033958133310079575, 0.053205832839012146, 0.042017195373773575, 0.02123786322772503, 0.013607077300548553, -0.013604682870209217, -0.022964950650930405, -0.01556775439530611], [0.022765811532735825, -0.015123708173632622, 0.012244660407304764, 0.056016966700553894, -0.04582544416189194, 0.005189047195017338, -0.04128553345799446, 0.03271813318133354, 0.0007758447318337858], [-0.04213739559054375, 0.021360447630286217, 0.03267262130975723, 0.05536723509430885, 0.01134566031396389, -0.00963268056511879, 0.044801805168390274, -0.040500372648239136, 0.05048643797636032], [0.025537874549627304, 0.03253061696887016, 0.017411110922694206, 0.03886476159095764, -0.012618038803339005, -0.027529319748282433, -0.03048194758594036, -0.05375642701983452, 0.013687935657799244], [0.05816677212715149, 0.048228681087493896, 0.004256096668541431, -0.04231143370270729, -0.05761917680501938, 0.0019908195827156305, -0.03649340942502022, -0.06068708002567291, 0.04255332425236702], [0.010016627609729767, -0.041266199201345444, -0.03866259381175041, -0.0072082881815731525, -0.007421719841659069, 0.045118898153305054, 0.03770004212856293, 0.0569547563791275, -0.0045676641166210175], [0.015209418721497059, 0.013036558404564857, 0.025425195693969727, 0.031962595880031586, 0.055960241705179214, -0.0226454921066761, 0.02868758514523506, 0.0586838498711586, -0.010908321477472782], [0.027480043470859528, 0.04643521457910538, 0.04614896699786186, -0.05271430313587189, -0.010922830551862717, 0.05201168730854988, 0.015166817232966423, 0.035418834537267685, -0.01212415099143982]]], [[[-0.03548387438058853, -0.042521581053733826, 0.0044430517591536045, 0.04627595469355583, -0.03532065451145172, 0.022845670580863953, 0.007194217294454575, 0.048957616090774536, -0.004721544217318296], [-0.017810676246881485, 0.033958133310079575, 0.053205832839012146, 0.042017195373773575, 0.02123786322772503, 0.013607077300548553, -0.013604682870209217, -0.022964950650930405, -0.01556775439530611], [0.022765811532735825, -0.015123708173632622, 0.012244660407304764, 0.056016966700553894, -0.04582544416189194, 0.005189047195017338, -0.04128553345799446, 0.03271813318133354, 0.0007758447318337858], [-0.04213739559054375, 0.021360447630286217, 0.03267262130975723, 0.05536723509430885, 0.01134566031396389, -0.00963268056511879, 0.044801805168390274, -0.040500372648239136, 0.05048643797636032], [0.025537874549627304, 0.03253061696887016, 0.017411110922694206, 0.03886476159095764, -0.012618038803339005, -0.027529319748282433, -0.03048194758594036, -0.05375642701983452, 0.013687935657799244], [0.05816677212715149, 0.048228681087493896, 0.004256096668541431, -0.04231143370270729, -0.05761917680501938, 0.0019908195827156305, -0.03649340942502022, -0.06068708002567291, 0.04255332425236702], [0.010016627609729767, -0.041266199201345444, -0.03866259381175041, -0.0072082881815731525, -0.007421719841659069, 0.045118898153305054, 0.03770004212856293, 0.0569547563791275, -0.0045676641166210175], [0.015209418721497059, 0.013036558404564857, 0.025425195693969727, 0.031962595880031586, 0.055960241705179214, -0.0226454921066761, 0.02868758514523506, 0.0586838498711586, -0.010908321477472782], [0.027480043470859528, 0.04643521457910538, 0.04614896699786186, -0.05271430313587189, -0.010922830551862717, 0.05201168730854988, 0.015166817232966423, 0.035418834537267685, -0.01212415099143982]]], [[[0.051469892263412476, 0.052286844700574875, 0.02002793923020363, -0.004909202456474304, -0.006720792967826128, -0.014952220022678375, -0.026707693934440613, -0.047476623207330704, 0.015369576402008533], [0.0014253652188926935, 0.05674656853079796, -0.059787776321172714, -0.018311360850930214, -0.01785452663898468, -0.02683529257774353, 0.04082324728369713, 0.030714135617017746, -0.04975946992635727], [-0.03206341341137886, -0.025943012908101082, 0.02292110025882721, -0.0496586374938488, -0.04291991516947746, 0.00032013474265113473, 4.2909886133202235e-07, 0.06281249970197678, 0.012425843626260757], [0.05593203753232956, -0.0041548409499228, 0.018936295062303543, 0.018262699246406555, -0.023640785366296768, -0.0057681226171553135, 0.017314523458480835, -0.019314050674438477, -0.004016254097223282], [-0.052703823894262314, 0.05587068945169449, -0.032096561044454575, -0.03959248214960098, 0.05592754855751991, 0.05160374939441681, 0.026542406529188156, 0.05035382881760597, -0.028595615178346634], [0.01494954526424408, 0.040805887430906296, -0.004309144802391529, 0.013384773395955563, 0.028972210362553596, 0.03610267490148544, -0.00012809212785214186, 0.050759896636009216, 0.04246322438120842], [0.008559482172131538, 0.021992014721035957, 0.054061148315668106, 0.03677253797650337, -0.0578303337097168, -0.030407404527068138, -0.052945539355278015, -0.001288437400944531, -0.04154461622238159], [0.008520887233316898, 0.004850682336837053, 0.03766248747706413, 0.04065120592713356, 0.04406224563717842, 0.019986813887953758, 0.004251865670084953, 0.025602133944630623, 0.00012388353934511542], [-0.05652898550033569, -0.002843588124960661, -0.02881769835948944, 0.0014639428118243814, 0.05251852422952652, 0.038176361471414566, 0.008745318278670311, 0.02489195577800274, 0.042926687747240067]]], [[[0.051469892263412476, 0.052286844700574875, 0.02002793923020363, -0.004909202456474304, -0.006720792967826128, -0.014952220022678375, -0.026707693934440613, -0.047476623207330704, 0.015369576402008533], [0.0014253652188926935, 0.05674656853079796, -0.059787776321172714, -0.018311360850930214, -0.01785452663898468, -0.02683529257774353, 0.04082324728369713, 0.030714135617017746, -0.04975946992635727], [-0.03206341341137886, -0.025943012908101082, 0.02292110025882721, -0.0496586374938488, -0.04291991516947746, 0.00032013474265113473, 4.2909886133202235e-07, 0.06281249970197678, 0.012425843626260757], [0.05593203753232956, -0.0041548409499228, 0.018936295062303543, 0.018262699246406555, -0.023640785366296768, -0.0057681226171553135, 0.017314523458480835, -0.019314050674438477, -0.004016254097223282], [-0.052703823894262314, 0.05587068945169449, -0.032096561044454575, -0.03959248214960098, 0.05592754855751991, 0.05160374939441681, 0.026542406529188156, 0.05035382881760597, -0.028595615178346634], [0.01494954526424408, 0.040805887430906296, -0.004309144802391529, 0.013384773395955563, 0.028972210362553596, 0.03610267490148544, -0.00012809212785214186, 0.050759896636009216, 0.04246322438120842], [0.008559482172131538, 0.021992014721035957, 0.054061148315668106, 0.03677253797650337, -0.0578303337097168, -0.030407404527068138, -0.052945539355278015, -0.001288437400944531, -0.04154461622238159], [0.008520887233316898, 0.004850682336837053, 0.03766248747706413, 0.04065120592713356, 0.04406224563717842, 0.019986813887953758, 0.004251865670084953, 0.025602133944630623, 0.00012388353934511542], [-0.05652898550033569, -0.002843588124960661, -0.02881769835948944, 0.0014639428118243814, 0.05251852422952652, 0.038176361471414566, 0.008745318278670311, 0.02489195577800274, 0.042926687747240067]]], [[[0.0052259680815041065, 0.045794352889060974, -0.04105469584465027, 0.05262592434883118, -0.02401668392121792, 0.05441063269972801, 0.060589443892240524, 0.021961824968457222, 0.022599276155233383], [-0.02428032085299492, -0.03307895362377167, -0.0006234286120161414, 0.03649379312992096, 0.04348144307732582, 0.003361984621733427, -0.020813075825572014, 0.024689806625247, 0.01654212921857834], [-0.04453173279762268, 0.05940503999590874, 0.05277438834309578, 0.040633026510477066, -0.046007461845874786, 0.03888004645705223, 0.037534672766923904, 0.03896976262331009, -0.05264279246330261], [-0.002690255409106612, 0.02277996577322483, 0.04816403612494469, -0.0015539928572252393, -0.03089546039700508, 0.016890879720449448, -0.018179921433329582, -0.045571304857730865, 0.04065084084868431], [-0.011556706391274929, -0.03534108027815819, -0.03592885658144951, 0.029280710965394974, 0.05251219496130943, 0.05182589963078499, 0.02768867462873459, 0.06048053875565529, -0.03941204026341438], [-0.058798518031835556, -0.018253521993756294, -0.001326328027062118, -0.04936020448803902, 0.03735584020614624, 0.01405314914882183, 0.012915989384055138, 0.02099248766899109, -0.0473749004304409], [0.03848026692867279, -0.00460826838389039, 0.05137873813509941, 0.03357228636741638, 0.041668713092803955, -0.044401902705430984, 0.009021175093948841, 0.05532311275601387, -0.016566451638936996], [-0.05380712449550629, 0.034717265516519547, 0.0603206530213356, 0.04277373105287552, -0.0015318978112190962, -0.009748152457177639, -0.025923823937773705, -0.041774261742830276, 0.05006357654929161], [-0.026659423485398293, 0.019967254251241684, -0.05634378269314766, -0.041083984076976776, -0.04146142303943634, -0.04872884228825569, 0.053730081766843796, 0.03482665866613388, -0.024065829813480377]]], [[[0.0052259680815041065, 0.045794352889060974, -0.04105469584465027, 0.05262592434883118, -0.02401668392121792, 0.05441063269972801, 0.060589443892240524, 0.021961824968457222, 0.022599276155233383], [-0.02428032085299492, -0.03307895362377167, -0.0006234286120161414, 0.03649379312992096, 0.04348144307732582, 0.003361984621733427, -0.020813075825572014, 0.024689806625247, 0.01654212921857834], [-0.04453173279762268, 0.05940503999590874, 0.05277438834309578, 0.040633026510477066, -0.046007461845874786, 0.03888004645705223, 0.037534672766923904, 0.03896976262331009, -0.05264279246330261], [-0.002690255409106612, 0.02277996577322483, 0.04816403612494469, -0.0015539928572252393, -0.03089546039700508, 0.016890879720449448, -0.018179921433329582, -0.045571304857730865, 0.04065084084868431], [-0.011556706391274929, -0.03534108027815819, -0.03592885658144951, 0.029280710965394974, 0.05251219496130943, 0.05182589963078499, 0.02768867462873459, 0.06048053875565529, -0.03941204026341438], [-0.058798518031835556, -0.018253521993756294, -0.001326328027062118, -0.04936020448803902, 0.03735584020614624, 0.01405314914882183, 0.012915989384055138, 0.02099248766899109, -0.0473749004304409], [0.03848026692867279, -0.00460826838389039, 0.05137873813509941, 0.03357228636741638, 0.041668713092803955, -0.044401902705430984, 0.009021175093948841, 0.05532311275601387, -0.016566451638936996], [-0.05380712449550629, 0.034717265516519547, 0.0603206530213356, 0.04277373105287552, -0.0015318978112190962, -0.009748152457177639, -0.025923823937773705, -0.041774261742830276, 0.05006357654929161], [-0.026659423485398293, 0.019967254251241684, -0.05634378269314766, -0.041083984076976776, -0.04146142303943634, -0.04872884228825569, 0.053730081766843796, 0.03482665866613388, -0.024065829813480377]]]], \"left_text\": [\"i \", \"liked \", \"the \", \"movie \", \"i \", \"saw \", \"in \", \"the \", \"cinema\"], \"right_text\": [\"i \", \"liked \", \"the \", \"movie \", \"i \", \"saw \", \"in \", \"the \", \"cinema\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-ca6f7496c1df4774ac9b5b0d3833bd4b\", \"layer\": null, \"heads\": null, \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7]}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[0.005308747757226229, 0.02792586013674736, 0.012444875203073025, 0.051662642508745193, -0.032666902989149094, 0.03962425887584686, -0.06341620534658432, -0.034399811178445816, -0.029896222054958344], [0.01534015592187643, -0.05293969064950943, 0.04813876748085022, 0.04369467496871948, -0.038243576884269714, 0.047391992062330246, 0.045103419572114944, -0.024966251105070114, -0.02024153061211109], [0.005885178688913584, 0.05363861843943596, 0.056672170758247375, -0.03855070844292641, 0.04591817036271095, -0.04247843101620674, -0.024459481239318848, 0.02769896574318409, -0.014317071065306664], [-0.0594935268163681, 0.01567590981721878, -0.0054655964486300945, 0.03161740303039551, 0.023045942187309265, -0.010685225948691368, -0.00529899587854743, 0.03432264178991318, 0.04537812992930412], [-0.056299641728401184, 0.013876128941774368, -0.04355517029762268, 0.018834900110960007, -0.021165167912840843, -0.03942957520484924, 0.04956173524260521, -0.049048151820898056, -0.002499617636203766], [0.04833441972732544, -0.012594245374202728, 0.013872274197638035, -0.04767740145325661, 0.003250666195526719, -0.036340706050395966, -0.05191194266080856, 0.018004637211561203, 0.003871646709740162], [0.017765672877430916, 0.03296053782105446, 0.05163554474711418, 0.021378953009843826, -0.056017663329839706, -0.0029373024590313435, -0.05167132243514061, -0.014652512036263943, -0.04398360475897789], [-0.05875718221068382, 0.013315537944436073, -0.028150252997875214, -0.04426280036568642, 0.046556778252124786, -0.03432033583521843, 0.03840509057044983, 0.0370270274579525, 0.009281065315008163], [0.0508430115878582, 0.010180911980569363, 0.024445349350571632, -0.06080879271030426, -0.03303331881761551, 0.006515083368867636, 0.017452266067266464, 0.021060768514871597, 0.05783354490995407]]], [[[0.005308747757226229, 0.02792586013674736, 0.012444875203073025, 0.051662642508745193, -0.032666902989149094, 0.03962425887584686, -0.06341620534658432, -0.034399811178445816, -0.029896222054958344], [0.01534015592187643, -0.05293969064950943, 0.04813876748085022, 0.04369467496871948, -0.038243576884269714, 0.047391992062330246, 0.045103419572114944, -0.024966251105070114, -0.02024153061211109], [0.005885178688913584, 0.05363861843943596, 0.056672170758247375, -0.03855070844292641, 0.04591817036271095, -0.04247843101620674, -0.024459481239318848, 0.02769896574318409, -0.014317071065306664], [-0.0594935268163681, 0.01567590981721878, -0.0054655964486300945, 0.03161740303039551, 0.023045942187309265, -0.010685225948691368, -0.00529899587854743, 0.03432264178991318, 0.04537812992930412], [-0.056299641728401184, 0.013876128941774368, -0.04355517029762268, 0.018834900110960007, -0.021165167912840843, -0.03942957520484924, 0.04956173524260521, -0.049048151820898056, -0.002499617636203766], [0.04833441972732544, -0.012594245374202728, 0.013872274197638035, -0.04767740145325661, 0.003250666195526719, -0.036340706050395966, -0.05191194266080856, 0.018004637211561203, 0.003871646709740162], [0.017765672877430916, 0.03296053782105446, 0.05163554474711418, 0.021378953009843826, -0.056017663329839706, -0.0029373024590313435, -0.05167132243514061, -0.014652512036263943, -0.04398360475897789], [-0.05875718221068382, 0.013315537944436073, -0.028150252997875214, -0.04426280036568642, 0.046556778252124786, -0.03432033583521843, 0.03840509057044983, 0.0370270274579525, 0.009281065315008163], [0.0508430115878582, 0.010180911980569363, 0.024445349350571632, -0.06080879271030426, -0.03303331881761551, 0.006515083368867636, 0.017452266067266464, 0.021060768514871597, 0.05783354490995407]]], [[[-0.03548387438058853, -0.042521581053733826, 0.0044430517591536045, 0.04627595469355583, -0.03532065451145172, 0.022845670580863953, 0.007194217294454575, 0.048957616090774536, -0.004721544217318296], [-0.017810676246881485, 0.033958133310079575, 0.053205832839012146, 0.042017195373773575, 0.02123786322772503, 0.013607077300548553, -0.013604682870209217, -0.022964950650930405, -0.01556775439530611], [0.022765811532735825, -0.015123708173632622, 0.012244660407304764, 0.056016966700553894, -0.04582544416189194, 0.005189047195017338, -0.04128553345799446, 0.03271813318133354, 0.0007758447318337858], [-0.04213739559054375, 0.021360447630286217, 0.03267262130975723, 0.05536723509430885, 0.01134566031396389, -0.00963268056511879, 0.044801805168390274, -0.040500372648239136, 0.05048643797636032], [0.025537874549627304, 0.03253061696887016, 0.017411110922694206, 0.03886476159095764, -0.012618038803339005, -0.027529319748282433, -0.03048194758594036, -0.05375642701983452, 0.013687935657799244], [0.05816677212715149, 0.048228681087493896, 0.004256096668541431, -0.04231143370270729, -0.05761917680501938, 0.0019908195827156305, -0.03649340942502022, -0.06068708002567291, 0.04255332425236702], [0.010016627609729767, -0.041266199201345444, -0.03866259381175041, -0.0072082881815731525, -0.007421719841659069, 0.045118898153305054, 0.03770004212856293, 0.0569547563791275, -0.0045676641166210175], [0.015209418721497059, 0.013036558404564857, 0.025425195693969727, 0.031962595880031586, 0.055960241705179214, -0.0226454921066761, 0.02868758514523506, 0.0586838498711586, -0.010908321477472782], [0.027480043470859528, 0.04643521457910538, 0.04614896699786186, -0.05271430313587189, -0.010922830551862717, 0.05201168730854988, 0.015166817232966423, 0.035418834537267685, -0.01212415099143982]]], [[[-0.03548387438058853, -0.042521581053733826, 0.0044430517591536045, 0.04627595469355583, -0.03532065451145172, 0.022845670580863953, 0.007194217294454575, 0.048957616090774536, -0.004721544217318296], [-0.017810676246881485, 0.033958133310079575, 0.053205832839012146, 0.042017195373773575, 0.02123786322772503, 0.013607077300548553, -0.013604682870209217, -0.022964950650930405, -0.01556775439530611], [0.022765811532735825, -0.015123708173632622, 0.012244660407304764, 0.056016966700553894, -0.04582544416189194, 0.005189047195017338, -0.04128553345799446, 0.03271813318133354, 0.0007758447318337858], [-0.04213739559054375, 0.021360447630286217, 0.03267262130975723, 0.05536723509430885, 0.01134566031396389, -0.00963268056511879, 0.044801805168390274, -0.040500372648239136, 0.05048643797636032], [0.025537874549627304, 0.03253061696887016, 0.017411110922694206, 0.03886476159095764, -0.012618038803339005, -0.027529319748282433, -0.03048194758594036, -0.05375642701983452, 0.013687935657799244], [0.05816677212715149, 0.048228681087493896, 0.004256096668541431, -0.04231143370270729, -0.05761917680501938, 0.0019908195827156305, -0.03649340942502022, -0.06068708002567291, 0.04255332425236702], [0.010016627609729767, -0.041266199201345444, -0.03866259381175041, -0.0072082881815731525, -0.007421719841659069, 0.045118898153305054, 0.03770004212856293, 0.0569547563791275, -0.0045676641166210175], [0.015209418721497059, 0.013036558404564857, 0.025425195693969727, 0.031962595880031586, 0.055960241705179214, -0.0226454921066761, 0.02868758514523506, 0.0586838498711586, -0.010908321477472782], [0.027480043470859528, 0.04643521457910538, 0.04614896699786186, -0.05271430313587189, -0.010922830551862717, 0.05201168730854988, 0.015166817232966423, 0.035418834537267685, -0.01212415099143982]]], [[[0.051469892263412476, 0.052286844700574875, 0.02002793923020363, -0.004909202456474304, -0.006720792967826128, -0.014952220022678375, -0.026707693934440613, -0.047476623207330704, 0.015369576402008533], [0.0014253652188926935, 0.05674656853079796, -0.059787776321172714, -0.018311360850930214, -0.01785452663898468, -0.02683529257774353, 0.04082324728369713, 0.030714135617017746, -0.04975946992635727], [-0.03206341341137886, -0.025943012908101082, 0.02292110025882721, -0.0496586374938488, -0.04291991516947746, 0.00032013474265113473, 4.2909886133202235e-07, 0.06281249970197678, 0.012425843626260757], [0.05593203753232956, -0.0041548409499228, 0.018936295062303543, 0.018262699246406555, -0.023640785366296768, -0.0057681226171553135, 0.017314523458480835, -0.019314050674438477, -0.004016254097223282], [-0.052703823894262314, 0.05587068945169449, -0.032096561044454575, -0.03959248214960098, 0.05592754855751991, 0.05160374939441681, 0.026542406529188156, 0.05035382881760597, -0.028595615178346634], [0.01494954526424408, 0.040805887430906296, -0.004309144802391529, 0.013384773395955563, 0.028972210362553596, 0.03610267490148544, -0.00012809212785214186, 0.050759896636009216, 0.04246322438120842], [0.008559482172131538, 0.021992014721035957, 0.054061148315668106, 0.03677253797650337, -0.0578303337097168, -0.030407404527068138, -0.052945539355278015, -0.001288437400944531, -0.04154461622238159], [0.008520887233316898, 0.004850682336837053, 0.03766248747706413, 0.04065120592713356, 0.04406224563717842, 0.019986813887953758, 0.004251865670084953, 0.025602133944630623, 0.00012388353934511542], [-0.05652898550033569, -0.002843588124960661, -0.02881769835948944, 0.0014639428118243814, 0.05251852422952652, 0.038176361471414566, 0.008745318278670311, 0.02489195577800274, 0.042926687747240067]]], [[[0.051469892263412476, 0.052286844700574875, 0.02002793923020363, -0.004909202456474304, -0.006720792967826128, -0.014952220022678375, -0.026707693934440613, -0.047476623207330704, 0.015369576402008533], [0.0014253652188926935, 0.05674656853079796, -0.059787776321172714, -0.018311360850930214, -0.01785452663898468, -0.02683529257774353, 0.04082324728369713, 0.030714135617017746, -0.04975946992635727], [-0.03206341341137886, -0.025943012908101082, 0.02292110025882721, -0.0496586374938488, -0.04291991516947746, 0.00032013474265113473, 4.2909886133202235e-07, 0.06281249970197678, 0.012425843626260757], [0.05593203753232956, -0.0041548409499228, 0.018936295062303543, 0.018262699246406555, -0.023640785366296768, -0.0057681226171553135, 0.017314523458480835, -0.019314050674438477, -0.004016254097223282], [-0.052703823894262314, 0.05587068945169449, -0.032096561044454575, -0.03959248214960098, 0.05592754855751991, 0.05160374939441681, 0.026542406529188156, 0.05035382881760597, -0.028595615178346634], [0.01494954526424408, 0.040805887430906296, -0.004309144802391529, 0.013384773395955563, 0.028972210362553596, 0.03610267490148544, -0.00012809212785214186, 0.050759896636009216, 0.04246322438120842], [0.008559482172131538, 0.021992014721035957, 0.054061148315668106, 0.03677253797650337, -0.0578303337097168, -0.030407404527068138, -0.052945539355278015, -0.001288437400944531, -0.04154461622238159], [0.008520887233316898, 0.004850682336837053, 0.03766248747706413, 0.04065120592713356, 0.04406224563717842, 0.019986813887953758, 0.004251865670084953, 0.025602133944630623, 0.00012388353934511542], [-0.05652898550033569, -0.002843588124960661, -0.02881769835948944, 0.0014639428118243814, 0.05251852422952652, 0.038176361471414566, 0.008745318278670311, 0.02489195577800274, 0.042926687747240067]]], [[[0.0052259680815041065, 0.045794352889060974, -0.04105469584465027, 0.05262592434883118, -0.02401668392121792, 0.05441063269972801, 0.060589443892240524, 0.021961824968457222, 0.022599276155233383], [-0.02428032085299492, -0.03307895362377167, -0.0006234286120161414, 0.03649379312992096, 0.04348144307732582, 0.003361984621733427, -0.020813075825572014, 0.024689806625247, 0.01654212921857834], [-0.04453173279762268, 0.05940503999590874, 0.05277438834309578, 0.040633026510477066, -0.046007461845874786, 0.03888004645705223, 0.037534672766923904, 0.03896976262331009, -0.05264279246330261], [-0.002690255409106612, 0.02277996577322483, 0.04816403612494469, -0.0015539928572252393, -0.03089546039700508, 0.016890879720449448, -0.018179921433329582, -0.045571304857730865, 0.04065084084868431], [-0.011556706391274929, -0.03534108027815819, -0.03592885658144951, 0.029280710965394974, 0.05251219496130943, 0.05182589963078499, 0.02768867462873459, 0.06048053875565529, -0.03941204026341438], [-0.058798518031835556, -0.018253521993756294, -0.001326328027062118, -0.04936020448803902, 0.03735584020614624, 0.01405314914882183, 0.012915989384055138, 0.02099248766899109, -0.0473749004304409], [0.03848026692867279, -0.00460826838389039, 0.05137873813509941, 0.03357228636741638, 0.041668713092803955, -0.044401902705430984, 0.009021175093948841, 0.05532311275601387, -0.016566451638936996], [-0.05380712449550629, 0.034717265516519547, 0.0603206530213356, 0.04277373105287552, -0.0015318978112190962, -0.009748152457177639, -0.025923823937773705, -0.041774261742830276, 0.05006357654929161], [-0.026659423485398293, 0.019967254251241684, -0.05634378269314766, -0.041083984076976776, -0.04146142303943634, -0.04872884228825569, 0.053730081766843796, 0.03482665866613388, -0.024065829813480377]]], [[[0.0052259680815041065, 0.045794352889060974, -0.04105469584465027, 0.05262592434883118, -0.02401668392121792, 0.05441063269972801, 0.060589443892240524, 0.021961824968457222, 0.022599276155233383], [-0.02428032085299492, -0.03307895362377167, -0.0006234286120161414, 0.03649379312992096, 0.04348144307732582, 0.003361984621733427, -0.020813075825572014, 0.024689806625247, 0.01654212921857834], [-0.04453173279762268, 0.05940503999590874, 0.05277438834309578, 0.040633026510477066, -0.046007461845874786, 0.03888004645705223, 0.037534672766923904, 0.03896976262331009, -0.05264279246330261], [-0.002690255409106612, 0.02277996577322483, 0.04816403612494469, -0.0015539928572252393, -0.03089546039700508, 0.016890879720449448, -0.018179921433329582, -0.045571304857730865, 0.04065084084868431], [-0.011556706391274929, -0.03534108027815819, -0.03592885658144951, 0.029280710965394974, 0.05251219496130943, 0.05182589963078499, 0.02768867462873459, 0.06048053875565529, -0.03941204026341438], [-0.058798518031835556, -0.018253521993756294, -0.001326328027062118, -0.04936020448803902, 0.03735584020614624, 0.01405314914882183, 0.012915989384055138, 0.02099248766899109, -0.0473749004304409], [0.03848026692867279, -0.00460826838389039, 0.05137873813509941, 0.03357228636741638, 0.041668713092803955, -0.044401902705430984, 0.009021175093948841, 0.05532311275601387, -0.016566451638936996], [-0.05380712449550629, 0.034717265516519547, 0.0603206530213356, 0.04277373105287552, -0.0015318978112190962, -0.009748152457177639, -0.025923823937773705, -0.041774261742830276, 0.05006357654929161], [-0.026659423485398293, 0.019967254251241684, -0.05634378269314766, -0.041083984076976776, -0.04146142303943634, -0.04872884228825569, 0.053730081766843796, 0.03482665866613388, -0.024065829813480377]]]], \"left_text\": [\"i \", \"liked \", \"the \", \"movie \", \"i \", \"saw \", \"in \", \"the \", \"cinema\"], \"right_text\": [\"i \", \"liked \", \"the \", \"movie \", \"i \", \"saw \", \"in \", \"the \", \"cinema\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-ca6f7496c1df4774ac9b5b0d3833bd4b\", \"layer\": null, \"heads\": null, \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7]} is a template marker that is replaced by actual params.\n",
       "    const TEXT_SIZE = 15;\n",
       "    const BOXWIDTH = 110;\n",
       "    const BOXHEIGHT = 22.5;\n",
       "    const MATRIX_WIDTH = 115;\n",
       "    const CHECKBOX_SIZE = 20;\n",
       "    const TEXT_TOP = 30;\n",
       "\n",
       "    console.log(\"d3 version\", d3.version)\n",
       "    let headColors;\n",
       "    try {\n",
       "        headColors = d3.scaleOrdinal(d3.schemeCategory10);\n",
       "    } catch (err) {\n",
       "        console.log('Older d3 version')\n",
       "        headColors = d3.scale.category10();\n",
       "    }\n",
       "    let config = {};\n",
       "    initialize();\n",
       "    renderVis();\n",
       "\n",
       "    function initialize() {\n",
       "        config.attention = params['attention'];\n",
       "        config.filter = params['default_filter'];\n",
       "        config.rootDivId = params['root_div_id'];\n",
       "        config.nLayers = config.attention[config.filter]['attn'].length;\n",
       "        config.nHeads = config.attention[config.filter]['attn'][0].length;\n",
       "        config.layers = params['include_layers']\n",
       "\n",
       "        if (params['heads']) {\n",
       "            config.headVis = new Array(config.nHeads).fill(false);\n",
       "            params['heads'].forEach(x => config.headVis[x] = true);\n",
       "        } else {\n",
       "            config.headVis = new Array(config.nHeads).fill(true);\n",
       "        }\n",
       "        config.initialTextLength = config.attention[config.filter].right_text.length;\n",
       "        config.layer_seq = (params['layer'] == null ? 0 : config.layers.findIndex(layer => params['layer'] === layer));\n",
       "        config.layer = config.layers[config.layer_seq]\n",
       "\n",
       "        let layerEl = $(`#${config.rootDivId} #layer`);\n",
       "        for (const layer of config.layers) {\n",
       "            layerEl.append($(\"<option />\").val(layer).text(layer));\n",
       "        }\n",
       "        layerEl.val(config.layer).change();\n",
       "        layerEl.on('change', function (e) {\n",
       "            config.layer = +e.currentTarget.value;\n",
       "            config.layer_seq = config.layers.findIndex(layer => config.layer === layer);\n",
       "            renderVis();\n",
       "        });\n",
       "\n",
       "        $(`#${config.rootDivId} #filter`).on('change', function (e) {\n",
       "            config.filter = e.currentTarget.value;\n",
       "            renderVis();\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function renderVis() {\n",
       "\n",
       "        // Load parameters\n",
       "        const attnData = config.attention[config.filter];\n",
       "        const leftText = attnData.left_text;\n",
       "        const rightText = attnData.right_text;\n",
       "\n",
       "        // Select attention for given layer\n",
       "        const layerAttention = attnData.attn[config.layer_seq];\n",
       "\n",
       "        // Clear vis\n",
       "        $(`#${config.rootDivId} #vis`).empty();\n",
       "\n",
       "        // Determine size of visualization\n",
       "        const height = Math.max(leftText.length, rightText.length) * BOXHEIGHT + TEXT_TOP;\n",
       "        const svg = d3.select(`#${config.rootDivId} #vis`)\n",
       "            .append('svg')\n",
       "            .attr(\"width\", \"100%\")\n",
       "            .attr(\"height\", height + \"px\");\n",
       "\n",
       "        // Display tokens on left and right side of visualization\n",
       "        renderText(svg, leftText, true, layerAttention, 0);\n",
       "        renderText(svg, rightText, false, layerAttention, MATRIX_WIDTH + BOXWIDTH);\n",
       "\n",
       "        // Render attention arcs\n",
       "        renderAttention(svg, layerAttention);\n",
       "\n",
       "        // Draw squares at top of visualization, one for each head\n",
       "        drawCheckboxes(0, svg, layerAttention);\n",
       "    }\n",
       "\n",
       "    function renderText(svg, text, isLeft, attention, leftPos) {\n",
       "\n",
       "        const textContainer = svg.append(\"svg:g\")\n",
       "            .attr(\"id\", isLeft ? \"left\" : \"right\");\n",
       "\n",
       "        // Add attention highlights superimposed over words\n",
       "        textContainer.append(\"g\")\n",
       "            .classed(\"attentionBoxes\", true)\n",
       "            .selectAll(\"g\")\n",
       "            .data(attention)\n",
       "            .enter()\n",
       "            .append(\"g\")\n",
       "            .attr(\"head-index\", (d, i) => i)\n",
       "            .selectAll(\"rect\")\n",
       "            .data(d => isLeft ? d : transpose(d)) // if right text, transpose attention to get right-to-left weights\n",
       "            .enter()\n",
       "            .append(\"rect\")\n",
       "            .attr(\"x\", function () {\n",
       "                var headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
       "                return leftPos + boxOffsets(headIndex);\n",
       "            })\n",
       "            .attr(\"y\", (+1) * BOXHEIGHT)\n",
       "            .attr(\"width\", BOXWIDTH / activeHeads())\n",
       "            .attr(\"height\", BOXHEIGHT)\n",
       "            .attr(\"fill\", function () {\n",
       "                return headColors(+this.parentNode.getAttribute(\"head-index\"))\n",
       "            })\n",
       "            .style(\"opacity\", 0.0);\n",
       "\n",
       "        const tokenContainer = textContainer.append(\"g\").selectAll(\"g\")\n",
       "            .data(text)\n",
       "            .enter()\n",
       "            .append(\"g\");\n",
       "\n",
       "        // Add gray background that appears when hovering over text\n",
       "        tokenContainer.append(\"rect\")\n",
       "            .classed(\"background\", true)\n",
       "            .style(\"opacity\", 0.0)\n",
       "            .attr(\"fill\", \"lightgray\")\n",
       "            .attr(\"x\", leftPos)\n",
       "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
       "            .attr(\"width\", BOXWIDTH)\n",
       "            .attr(\"height\", BOXHEIGHT);\n",
       "\n",
       "        // Add token text\n",
       "        const textEl = tokenContainer.append(\"text\")\n",
       "            .text(d => d)\n",
       "            .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "            .style(\"cursor\", \"default\")\n",
       "            .style(\"-webkit-user-select\", \"none\")\n",
       "            .attr(\"x\", leftPos)\n",
       "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT);\n",
       "\n",
       "        if (isLeft) {\n",
       "            textEl.style(\"text-anchor\", \"end\")\n",
       "                .attr(\"dx\", BOXWIDTH - 0.5 * TEXT_SIZE)\n",
       "                .attr(\"dy\", TEXT_SIZE);\n",
       "        } else {\n",
       "            textEl.style(\"text-anchor\", \"start\")\n",
       "                .attr(\"dx\", +0.5 * TEXT_SIZE)\n",
       "                .attr(\"dy\", TEXT_SIZE);\n",
       "        }\n",
       "\n",
       "        tokenContainer.on(\"mouseover\", function (d, index) {\n",
       "\n",
       "            // Show gray background for moused-over token\n",
       "            textContainer.selectAll(\".background\")\n",
       "                .style(\"opacity\", (d, i) => i === index ? 1.0 : 0.0)\n",
       "\n",
       "            // Reset visibility attribute for any previously highlighted attention arcs\n",
       "            svg.select(\"#attention\")\n",
       "                .selectAll(\"line[visibility='visible']\")\n",
       "                .attr(\"visibility\", null)\n",
       "\n",
       "            // Hide group containing attention arcs\n",
       "            svg.select(\"#attention\").attr(\"visibility\", \"hidden\");\n",
       "\n",
       "            // Set to visible appropriate attention arcs to be highlighted\n",
       "            if (isLeft) {\n",
       "                svg.select(\"#attention\").selectAll(\"line[left-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
       "            } else {\n",
       "                svg.select(\"#attention\").selectAll(\"line[right-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
       "            }\n",
       "\n",
       "            // Update color boxes superimposed over tokens\n",
       "            const id = isLeft ? \"right\" : \"left\";\n",
       "            const leftPos = isLeft ? MATRIX_WIDTH + BOXWIDTH : 0;\n",
       "            svg.select(\"#\" + id)\n",
       "                .selectAll(\".attentionBoxes\")\n",
       "                .selectAll(\"g\")\n",
       "                .attr(\"head-index\", (d, i) => i)\n",
       "                .selectAll(\"rect\")\n",
       "                .attr(\"x\", function () {\n",
       "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
       "                    return leftPos + boxOffsets(headIndex);\n",
       "                })\n",
       "                .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
       "                .attr(\"width\", BOXWIDTH / activeHeads())\n",
       "                .attr(\"height\", BOXHEIGHT)\n",
       "                .style(\"opacity\", function (d) {\n",
       "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
       "                    if (config.headVis[headIndex])\n",
       "                        if (d) {\n",
       "                            return d[index];\n",
       "                        } else {\n",
       "                            return 0.0;\n",
       "                        }\n",
       "                    else\n",
       "                        return 0.0;\n",
       "                });\n",
       "        });\n",
       "\n",
       "        textContainer.on(\"mouseleave\", function () {\n",
       "\n",
       "            // Unhighlight selected token\n",
       "            d3.select(this).selectAll(\".background\")\n",
       "                .style(\"opacity\", 0.0);\n",
       "\n",
       "            // Reset visibility attributes for previously selected lines\n",
       "            svg.select(\"#attention\")\n",
       "                .selectAll(\"line[visibility='visible']\")\n",
       "                .attr(\"visibility\", null) ;\n",
       "            svg.select(\"#attention\").attr(\"visibility\", \"visible\");\n",
       "\n",
       "            // Reset highlights superimposed over tokens\n",
       "            svg.selectAll(\".attentionBoxes\")\n",
       "                .selectAll(\"g\")\n",
       "                .selectAll(\"rect\")\n",
       "                .style(\"opacity\", 0.0);\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function renderAttention(svg, attention) {\n",
       "\n",
       "        // Remove previous dom elements\n",
       "        svg.select(\"#attention\").remove();\n",
       "\n",
       "        // Add new elements\n",
       "        svg.append(\"g\")\n",
       "            .attr(\"id\", \"attention\") // Container for all attention arcs\n",
       "            .selectAll(\".headAttention\")\n",
       "            .data(attention)\n",
       "            .enter()\n",
       "            .append(\"g\")\n",
       "            .classed(\"headAttention\", true) // Group attention arcs by head\n",
       "            .attr(\"head-index\", (d, i) => i)\n",
       "            .selectAll(\".tokenAttention\")\n",
       "            .data(d => d)\n",
       "            .enter()\n",
       "            .append(\"g\")\n",
       "            .classed(\"tokenAttention\", true) // Group attention arcs by left token\n",
       "            .attr(\"left-token-index\", (d, i) => i)\n",
       "            .selectAll(\"line\")\n",
       "            .data(d => d)\n",
       "            .enter()\n",
       "            .append(\"line\")\n",
       "            .attr(\"x1\", BOXWIDTH)\n",
       "            .attr(\"y1\", function () {\n",
       "                const leftTokenIndex = +this.parentNode.getAttribute(\"left-token-index\")\n",
       "                return TEXT_TOP + leftTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2)\n",
       "            })\n",
       "            .attr(\"x2\", BOXWIDTH + MATRIX_WIDTH)\n",
       "            .attr(\"y2\", (d, rightTokenIndex) => TEXT_TOP + rightTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2))\n",
       "            .attr(\"stroke-width\", 2)\n",
       "            .attr(\"stroke\", function () {\n",
       "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
       "                return headColors(headIndex)\n",
       "            })\n",
       "            .attr(\"left-token-index\", function () {\n",
       "                return +this.parentNode.getAttribute(\"left-token-index\")\n",
       "            })\n",
       "            .attr(\"right-token-index\", (d, i) => i)\n",
       "        ;\n",
       "        updateAttention(svg)\n",
       "    }\n",
       "\n",
       "    function updateAttention(svg) {\n",
       "        svg.select(\"#attention\")\n",
       "            .selectAll(\"line\")\n",
       "            .attr(\"stroke-opacity\", function (d) {\n",
       "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
       "                // If head is selected\n",
       "                if (config.headVis[headIndex]) {\n",
       "                    // Set opacity to attention weight divided by number of active heads\n",
       "                    return d / activeHeads()\n",
       "                } else {\n",
       "                    return 0.0;\n",
       "                }\n",
       "            })\n",
       "    }\n",
       "\n",
       "    function boxOffsets(i) {\n",
       "        const numHeadsAbove = config.headVis.reduce(\n",
       "            function (acc, val, cur) {\n",
       "                return val && cur < i ? acc + 1 : acc;\n",
       "            }, 0);\n",
       "        return numHeadsAbove * (BOXWIDTH / activeHeads());\n",
       "    }\n",
       "\n",
       "    function activeHeads() {\n",
       "        return config.headVis.reduce(function (acc, val) {\n",
       "            return val ? acc + 1 : acc;\n",
       "        }, 0);\n",
       "    }\n",
       "\n",
       "    function drawCheckboxes(top, svg) {\n",
       "        const checkboxContainer = svg.append(\"g\");\n",
       "        const checkbox = checkboxContainer.selectAll(\"rect\")\n",
       "            .data(config.headVis)\n",
       "            .enter()\n",
       "            .append(\"rect\")\n",
       "            .attr(\"fill\", (d, i) => headColors(i))\n",
       "            .attr(\"x\", (d, i) => i * CHECKBOX_SIZE)\n",
       "            .attr(\"y\", top)\n",
       "            .attr(\"width\", CHECKBOX_SIZE)\n",
       "            .attr(\"height\", CHECKBOX_SIZE);\n",
       "\n",
       "        function updateCheckboxes() {\n",
       "            checkboxContainer.selectAll(\"rect\")\n",
       "                .data(config.headVis)\n",
       "                .attr(\"fill\", (d, i) => d ? headColors(i): lighten(headColors(i)));\n",
       "        }\n",
       "\n",
       "        updateCheckboxes();\n",
       "\n",
       "        checkbox.on(\"click\", function (d, i) {\n",
       "            if (config.headVis[i] && activeHeads() === 1) return;\n",
       "            config.headVis[i] = !config.headVis[i];\n",
       "            updateCheckboxes();\n",
       "            updateAttention(svg);\n",
       "        });\n",
       "\n",
       "        checkbox.on(\"dblclick\", function (d, i) {\n",
       "            // If we double click on the only active head then reset\n",
       "            if (config.headVis[i] && activeHeads() === 1) {\n",
       "                config.headVis = new Array(config.nHeads).fill(true);\n",
       "            } else {\n",
       "                config.headVis = new Array(config.nHeads).fill(false);\n",
       "                config.headVis[i] = true;\n",
       "            }\n",
       "            updateCheckboxes();\n",
       "            updateAttention(svg);\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function lighten(color) {\n",
       "        const c = d3.hsl(color);\n",
       "        const increment = (1 - c.l) * 0.6;\n",
       "        c.l += increment;\n",
       "        c.s -= increment;\n",
       "        return c;\n",
       "    }\n",
       "\n",
       "    function transpose(mat) {\n",
       "        return mat[0].map(function (col, i) {\n",
       "            return mat.map(function (row) {\n",
       "                return row[i];\n",
       "            });\n",
       "        });\n",
       "    }\n",
       "\n",
       "});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = \"I liked the movie I saw in the cinema\"\n",
    "toks, atts = get_att_tok(model, sentence.lower())\n",
    "call_html()\n",
    "head_view(atts, toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
